\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{color}


\begin{document}
Black: general information to consider. Blue: Sources are analysed. Red: Important Information (maybe quotation)
\begin{enumerate}
	\item[intro]
		\begin{enumerate}
			\item \textcolor{red}{\url{http://en.wikipedia.org/wiki/Stock_market_prediction}} intro, motivation
		\end{enumerate}
	\item[Linear regression]
		\begin{enumerate}
			\item \textcolor{blue}{\url{http://www.dummies.com/how-to/content/how-to-use-a-linear-regression-to-identify-market-.html}}
			\item \textcolor{blue}{\url{http://www.seas.upenn.edu/~ese302/Projects/Project_4.pdf}}
			\item \url{http://scientific-journals.org/journalofsystemsandsoftware/archive/vol1no4/vol1no4_6.pdf}
			\item \textcolor{red}{\url{http://airccse.org/journal/mvsc/papers/4313ijmvsc03.pdf}}
			\item \url{http://www.investopedia.com/university/technical/techanalysis5.asp}
			\item \url{http://en.wikipedia.org/wiki/Stock_market}
			\item \url{http://www.cabot.net/stock-market-advice/trading-volume}
			\item \url{http://www.streetdirectory.com/travel_guide/144293/trading/why_a_stocks_volume_is_important.html}
			\item \textcolor{red}{\url{http://www.investopedia.com/exam-guide/cfa-level-1/quantitative-methods/regression-analysis.asp}}
			\item \textcolor{red}{\url{http://www.investopedia.com/articles/trading/09/linear-regression-time-price.asp}}
			\item \textcolor{red}{\url{http://en.wikipedia.org/wiki/Linear_regression}}
			\item \textcolor{blue}{\url{http://www.advisorperspectives.com/dshort/updates/Regression-to-Trend.php}}
			\item \textcolor{blue}{\url{http://www.usbe.umu.se/digitalAssets/121/121508_ues860.pdf}}
		\end{enumerate}
	\item[Multiple linear regression]
		\begin{enumerate}
			\item \textcolor{blue}{\url{http://en.wikipedia.org/wiki/Regression_analysis}}
			\item \textcolor{red}{\url{http://www.statsoft.com/textbook/multiple-regression}} examples
			\item \textcolor{red}{\url{https://explorable.com/multiple-regression-analysis}} assumptions and tests
			\item \textcolor{black}{\url{http://people.stern.nyu.edu/wgreene/Statistics/MultipleRegressionBasicsCollection.pdf}}
			\item \textcolor{blue}{\url{http://www.stat.yale.edu/Courses/1997-98/101/linmult.htm}}
			\item \textcolor{black}{Dale E. Berger: Introduction to Multiple Regression} significance tests
			\item \textcolor{blue}{\url{http://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Multivariable/BS704_Multivariable7.html}} example
			\item \textcolor{red}{\url{http://reliawiki.org/index.php/Multiple_Linear_Regression_Analysis}} nice explanation of the cross-dependency
			\item \textcolor{blue}{\url{http://www.investopedia.com/terms/m/mlr.asp}}
			\item \textcolor{black}{\url{http://dept.stat.lsa.umich.edu/~kshedden/Courses/Stat401/Notes/401-multreg.pdf}} matrix form and example
			\item \textcolor{black}{\url{http://en.wikipedia.org/wiki/Analysis_of_variance}}
			\item \textcolor{black}{\url{http://en.wikipedia.org/wiki/F-test}}
		\end{enumerate} 
	\item[Non linear regression]
		\begin{enumerate}
			\item \textcolor{black}{\url{http://research.stlouisfed.org/wp/2008/2008-010.pdf}} stock exchange use
			\item \textcolor{black}{\url{eprints.ucm.es/16688/1/1224.pdf}} strategic and portfolio
			\item \textcolor{blue}{\url{http://www.investopedia.com/terms/n/nonlinear-regression.asp}}
			\item \textcolor{black}{\url{http://www.ijbhtnet.com/journals/Vol_3_No_3_March_2013/4.pdf}}
			\item \textcolor{black}{\url{http://www.aabri.com/manuscripts/131609.pdf}}
			\item \textcolor{black}{\url{http://mpra.ub.uni-muenchen.de/20738/ }}
			\item \textcolor{black}{\url{http://fbe.unimelb.edu.au/__data/assets/pdf_file/0007/805813/868.pdf}}
			\item \textcolor{red}{\url{http://cran.r-project.org/doc/contrib/Fox-Companion/appendix-nonlinear-regression.pdf}} definition, Likelihood, example in R
			\item \textcolor{red}{\url{http://hspm.sph.sc.edu/Courses/J716/pdf/716-5\%20Non-linear\%20regression.pdf}} example and simple explanation with bakteria
			\item \textcolor{red}{\url{http://www.graphpad.com/faq/file/Prism4RegressionBook.pdf}} example, definition, prism approach
			\item \textcolor{red}{\url{http://www.stat.colostate.edu/regression_book/chapter9.pdf}} hard to read, nice examples with graphs
			\item \textcolor{red}{\url{http://en.wikipedia.org/wiki/Gauss\%E2\%80\%93Newton_algorithm}} solving the nonlinear equations
			\item \textcolor{red}{\url{http://en.wikipedia.org/wiki/Levenberg\%E2\%80\%93Marquardt_algorithm}} solving the nonlinear equations
		\end{enumerate}
	\item[Neural networks]
		\begin{enumerate}
			\item \textcolor{red}{\url{http://en.wikipedia.org/wiki/Artificial_neural_network}} definition
			\item \textcolor{blue}{\url{http://www.investopedia.com/articles/trading/06/neuralnetworks.asp}}
			\item \textcolor{red}{\url{http://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol4/cs11/report.html}} lectures
			\item \textcolor{blue}{\url{http://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/Applications/stocks.html}} specification of the differnt learning approaches and structures.
			\item \textcolor{blue}{\url{http://neuroph.sourceforge.net/tutorials/StockMarketPredictionTutorial.html}} actual example with for DAX, using StockGenerator
			\item \textcolor{blue}{\url{http://www.alyuda.com/}} software, second step after Pulse?
			\item \textcolor{black}{\url{http://cims.nyu.edu/~ra1221/IIMA/ANN.pdf}} sentiment data analysis included into study in 2008
			\item \textcolor{red}{\url{http://nbviewer.ipython.org/github/jrosen3/cs109annstock/blob/master/Master.ipynb}} application on GitHub
			\item \textcolor{blue}{\url{http://www.eecs.harvard.edu/~parkes/cs286r/spring08/cours.pdf}} estimations for three-layered perceptron 
			\item \textcolor{blue}{\url{http://edoc.hu-berlin.de/master/giacomini-enzo-2003-12-23/PDF/giacomini.pdf}} specific example of a perceptron
			\item \textcolor{blue}{\url{http://link.springer.com/article/10.1186\%2F2251-712X-9-1\#page-1}} example of a perceptron for S\&P 500
			\item \textcolor{red}{\url{http://crpit.com/confpapers/CRPITV4Skabar.pdf}} print it, just interesting and easy reading
			\item \textcolor{red}{\url{http://ntnu.diva-portal.org/smash/get/diva2:353048/FULLTEXT01.pdf}} complete example from technical analysis to ANN use
		\end{enumerate}
	\item[Machine learning]
		\begin{enumerate}
			\item \textcolor{black}{\url{http://en.wikipedia.org/wiki/Machine_learning}}
			\item \textcolor{black}{\url{http://see.stanford.edu/see/lecturelist.aspx?coll=348ca38a-3a6d-4052-937d-cb017338d7b1}} full lectures
			\item \textcolor{black}{\url{http://eugenezhulenev.com/blog/2014/11/14/stock-price-prediction-with-big-data-and-machine-learning/}} example
			\item \textcolor{black}{\url{http://cs229.stanford.edu/proj2013/DaiZhang-MachineLearningInStockPriceTrendForecasting.pdf}}
			\item \textcolor{black}{\url{http://blog.andersen.im/wp-content/uploads/2012/12/ANovelAlgorithmicTradingFramework.pdf}}
			\item \textcolor{black}{\url{Trevor Hastie, "The Elements of statistical Learning: Data Mining, Inference, and Prediction" 2009}}
			\item \textcolor{black}{\url{https://quantumfinancier.wordpress.com/2010/06/26/support-vector-machine-rsi-system/}} vector support
			\item \textcolor{black}{\url{http://www.anlytcs.com/2014/01/stock-forecasting-with-machine-learning.html}} high frequency
			\item \textcolor{black}{\url{https://class.coursera.org/predmachlearn-010}} coursera, ML
			\item \textcolor{black}{\url{}}
			\item \textcolor{black}{\url{}}
		\end{enumerate}
		
	\item[Sentiment data analysis]
	\begin{enumerate}
		\item \textcolor{red}{\url{http://en.wikipedia.org/wiki/Sentiment_analysis}} definition, general info
		\item \textcolor{blue}{\url{http://nlp.stanford.edu/sentiment/}}
		\item \textcolor{black}{\url{https://semantria.com/sentiment-analysis}}
		\item \textcolor{black}{\url{https://cloud.google.com/prediction/docs/sentiment_analysis}}
		\item \textcolor{black}{\url{http://www.alchemyapi.com/products/alchemylanguage/sentiment-analysis/}}
		\item \textcolor{black}{\url{http://www.sas.com/en_us/software/analytics/sentiment-analysis.html}}
		\item \textcolor{black}{\url{http://www.lexalytics.com/technical-info/sentiment-analysis}}
		\item \textcolor{black}{\url{}}
	\end{enumerate}
	\item[Data collection]
		\begin{enumerate}
			\item \textcolor{red}{\url{http://www.graphpad.com/faq/file/Prism4RegressionBook.pdf}} data preprocessing
			\item \textcolor{black}{\url{http://www.wessa.net/finmardata.wasp}}
			\item \textcolor{black}{\url{http://datashop.deutsche-boerse.com/1003/en}}
			\item \textcolor{red}{\url{http://finance.yahoo.com/q/hp?s=INTC&a=00&b=01&c=2000&d=00&e=01&f=2015&g=d}} Intel (daily, 1.01.2000-1.01.2015) (the data checked with the data from Intel and nasdaq, was the most comfortable web site to get it downloaded)
			\item \textcolor{red}{\url{http://en.wikipedia.org/wiki/Semiconductor_sales_leaders_by_year}} competitors for Intel (chips market)
			\item \textcolor{black}{\url{}}
			\item \textcolor{black}{\url{}}
			\item \textcolor{black}{\url{}}
			\item \textcolor{black}{\url{}}
			\item \textcolor{black}{\url{}}
		\end{enumerate}
	\item[Additional]
		\begin{enumerate}
			\item \textcolor{black}{\url{http://en.wikipedia.org/wiki/Probit_model}} for binomial output
			\item \textcolor{black}{\url{http://en.wikipedia.org/wiki/Logistic_regression}}	binomial output
			\item \textcolor{black}{\url{http://en.wikipedia.org/wiki/Proportional_hazards_model}} survival model 
			\item \textcolor{black}{\url{http://de.wikipedia.org/wiki/Cox-Regression}} survival model
			\item \textcolor{black}{\url{}}
		\end{enumerate}
\end{enumerate}
\section*{Used literature in the text}
\begin{enumerate}
	\item Wikipedia, Multicollinearity \url{http://en.wikipedia.org/wiki/Multicollinearity}
	\item Wikipedia, AIC \url{http://en.wikipedia.org/wiki/Akaike_information_criterion}
	\item Kolmogorov's criterion \url{http://en.wikipedia.org/wiki/Kolmogorov\%27s_criterion}
	\item Stationarity \url{http://en.wikipedia.org/wiki/Stationary_process}
	\item Dickey-Fuller test \url{http://en.wikipedia.org/wiki/Dickey\%E2\%80\%93Fuller_test}
	\item Autocorrelation \url{http://en.wikipedia.org/wiki/Autocorrelation}
	\item Bereush-Godfrey test \url{http://en.wikipedia.org/wiki/Breusch\%E2\%80\%93Godfrey_test}
	\item CDF \url{http://en.wikipedia.org/wiki/Cumulative_distribution_function}
	\item KDE \url{http://en.wikipedia.org/wiki/Kernel_density_estimation}
	\item Critical values of the lognormal distribution \url{http://goo.gl/dAvu1t}
	\item Lognormal distribution \url{http://en.wikipedia.org/wiki/Log-normal_distribution}
	\item Likelihood ratio test \url{https://en.wikipedia.org/wiki/Likelihood-ratio_test}
	\item LLR test in use  \url{http://www.itl.nist.gov/div898/handbook/apr/section2/apr233.htm}

    \item LLR test in use 2  \url{http://isites.harvard.edu/fs/docs/icb.topic1383356.files/Lecture%2015%20-%20Likelihood%20Ratio%20Tests-%204%20per%20page.pdf}
\end{enumerate}

\newpage
\begin{verbatim}
Best 1-parameter model is: Olympus with 0.857338021369 correlation
The Null-Hypothesis is rejected
the bigger model is better. Search further ['St Jude', 'Olympus']
small model:                              GLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.987
Model:                            GLS   Adj. R-squared:                  0.987
Method:                 Least Squares   F-statistic:                 9.164e+04
Date:                Mon, 20 Jul 2015   Prob (F-statistic):               0.00
Time:                        14:32:44   Log-Likelihood:                -2826.9
No. Observations:                1239   AIC:                             5656.
Df Residuals:                    1238   BIC:                             5661.
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
x1             0.6779      0.002    302.714      0.000         0.673     0.682
==============================================================================
Omnibus:                       50.736   Durbin-Watson:                   0.054
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               59.153
Skew:                           0.458   Prob(JB):                     1.43e-13
Kurtosis:                       3.553   Cond. No.                         1.00
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
big model:                              GLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.995
Model:                            GLS   Adj. R-squared:                  0.995
Method:                 Least Squares   F-statistic:                 1.309e+05
Date:                Mon, 20 Jul 2015   Prob (F-statistic):               0.00
Time:                        14:32:44   Log-Likelihood:                -2181.4
No. Observations:                1239   AIC:                             4367.
Df Residuals:                    1237   BIC:                             4377.
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
x1             0.3518      0.007     50.439      0.000         0.338     0.365
x2             0.2523      0.005     47.640      0.000         0.242     0.263
==============================================================================
Omnibus:                       38.373   Durbin-Watson:                   0.092
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               41.152
Skew:                           0.438   Prob(JB):                     1.16e-09
Kurtosis:                       3.170   Cond. No.                         10.8
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
The Null-Hypothesis is rejected
the bigger model is better. Search further ['Lenovo', 'Olympus', 'St Jude']
small model:                              GLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.995
Model:                            GLS   Adj. R-squared:                  0.995
Method:                 Least Squares   F-statistic:                 1.309e+05
Date:                Mon, 20 Jul 2015   Prob (F-statistic):               0.00
Time:                        14:33:28   Log-Likelihood:                -2181.4
No. Observations:                1239   AIC:                             4367.
Df Residuals:                    1237   BIC:                             4377.
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
x1             0.3518      0.007     50.439      0.000         0.338     0.365
x2             0.2523      0.005     47.640      0.000         0.242     0.263
==============================================================================
Omnibus:                       38.373   Durbin-Watson:                   0.092
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               41.152
Skew:                           0.438   Prob(JB):                     1.16e-09
Kurtosis:                       3.170   Cond. No.                         10.8
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
big model:                              GLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.996
Model:                            GLS   Adj. R-squared:                  0.996
Method:                 Least Squares   F-statistic:                 1.150e+05
Date:                Mon, 20 Jul 2015   Prob (F-statistic):               0.00
Time:                        14:33:28   Log-Likelihood:                -2010.9
No. Observations:                1239   AIC:                             4028.
Df Residuals:                    1236   BIC:                             4043.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
x1             0.2547      0.013     19.788      0.000         0.229     0.280
x2             0.2619      0.008     34.505      0.000         0.247     0.277
x3             0.2518      0.005     54.520      0.000         0.243     0.261
==============================================================================
Omnibus:                       31.111   Durbin-Watson:                   0.108
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               34.831
Skew:                           0.343   Prob(JB):                     2.73e-08
Kurtosis:                       3.452   Cond. No.                         20.1
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
The Null-Hypothesis is rejected
the bigger model is better. Search further ['MicronTech', 'Olympus', 'St Jude', 'Lenovo']
small model:                              GLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.996
Model:                            GLS   Adj. R-squared:                  0.996
Method:                 Least Squares   F-statistic:                 1.150e+05
Date:                Mon, 20 Jul 2015   Prob (F-statistic):               0.00
Time:                        14:34:26   Log-Likelihood:                -2010.9
No. Observations:                1239   AIC:                             4028.
Df Residuals:                    1236   BIC:                             4043.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
x1             0.2547      0.013     19.788      0.000         0.229     0.280
x2             0.2619      0.008     34.505      0.000         0.247     0.277
x3             0.2518      0.005     54.520      0.000         0.243     0.261
==============================================================================
Omnibus:                       31.111   Durbin-Watson:                   0.108
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               34.831
Skew:                           0.343   Prob(JB):                     2.73e-08
Kurtosis:                       3.452   Cond. No.                         20.1
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
big model:                              GLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.997
Model:                            GLS   Adj. R-squared:                  0.997
Method:                 Least Squares   F-statistic:                 1.147e+05
Date:                Mon, 20 Jul 2015   Prob (F-statistic):               0.00
Time:                        14:34:26   Log-Likelihood:                -1834.1
No. Observations:                1239   AIC:                             3676.
Df Residuals:                    1235   BIC:                             3697.
Df Model:                           4                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
x1             0.3896      0.013     29.945      0.000         0.364     0.415
x2             0.1920      0.010     20.196      0.000         0.173     0.211
x3             0.1624      0.008     19.750      0.000         0.146     0.179
x4             0.2441      0.004     60.662      0.000         0.236     0.252
==============================================================================
Omnibus:                       13.979   Durbin-Watson:                   0.129
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               12.923
Skew:                           0.206   Prob(JB):                      0.00156
Kurtosis:                       2.715   Cond. No.                         26.9
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
The Null-Hypothesis is rejected
the bigger model is better. Search further ['Google', 'Olympus', 'St Jude', 'Lenovo', 'MicronTech']
small model:                              GLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.997
Model:                            GLS   Adj. R-squared:                  0.997
Method:                 Least Squares   F-statistic:                 1.147e+05
Date:                Mon, 20 Jul 2015   Prob (F-statistic):               0.00
Time:                        14:35:37   Log-Likelihood:                -1834.1
No. Observations:                1239   AIC:                             3676.
Df Residuals:                    1235   BIC:                             3697.
Df Model:                           4                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
x1             0.3896      0.013     29.945      0.000         0.364     0.415
x2             0.1920      0.010     20.196      0.000         0.173     0.211
x3             0.1624      0.008     19.750      0.000         0.146     0.179
x4             0.2441      0.004     60.662      0.000         0.236     0.252
==============================================================================
Omnibus:                       13.979   Durbin-Watson:                   0.129
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               12.923
Skew:                           0.206   Prob(JB):                      0.00156
Kurtosis:                       2.715   Cond. No.                         26.9
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
big model:                              GLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.998
Model:                            GLS   Adj. R-squared:                  0.998
Method:                 Least Squares   F-statistic:                 9.941e+04
Date:                Mon, 20 Jul 2015   Prob (F-statistic):               0.00
Time:                        14:35:37   Log-Likelihood:                -1784.1
No. Observations:                1239   AIC:                             3578.
Df Residuals:                    1234   BIC:                             3604.
Df Model:                           5                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
x1             0.0059      0.001     10.182      0.000         0.005     0.007
x2             0.2972      0.015     19.239      0.000         0.267     0.327
x3             0.1957      0.009     21.410      0.000         0.178     0.214
x4             0.1299      0.009     15.252      0.000         0.113     0.147
x5             0.2212      0.004     49.439      0.000         0.212     0.230
==============================================================================
Omnibus:                       23.730   Durbin-Watson:                   0.122
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               24.588
Skew:                           0.334   Prob(JB):                     4.58e-06
Kurtosis:                       3.171   Cond. No.                         276.
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
The Null-Hypothesis is rejected
the bigger model is better. Search further ['STMElectro', 'Olympus', 'St Jude', 'Lenovo', 'MicronTech', 'Google']

small model:                              GLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.998
Model:                            GLS   Adj. R-squared:                  0.998
Method:                 Least Squares   F-statistic:                 9.941e+04
Date:                Mon, 20 Jul 2015   Prob (F-statistic):               0.00
Time:                        14:37:03   Log-Likelihood:                -1784.1
No. Observations:                1239   AIC:                             3578.
Df Residuals:                    1234   BIC:                             3604.
Df Model:                           5                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
x1             0.0059      0.001     10.182      0.000         0.005     0.007
x2             0.2972      0.015     19.239      0.000         0.267     0.327
x3             0.1957      0.009     21.410      0.000         0.178     0.214
x4             0.1299      0.009     15.252      0.000         0.113     0.147
x5             0.2212      0.004     49.439      0.000         0.212     0.230
==============================================================================
Omnibus:                       23.730   Durbin-Watson:                   0.122
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               24.588
Skew:                           0.334   Prob(JB):                     4.58e-06
Kurtosis:                       3.171   Cond. No.                         276.
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
big model:                              GLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.998
Model:                            GLS   Adj. R-squared:                  0.998
Method:                 Least Squares   F-statistic:                 8.701e+04
Date:                Mon, 20 Jul 2015   Prob (F-statistic):               0.00
Time:                        14:37:03   Log-Likelihood:                -1753.3
No. Observations:                1239   AIC:                             3519.
Df Residuals:                    1233   BIC:                             3549.
Df Model:                           6                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
x1             0.0083      0.001     12.929      0.000         0.007     0.010
x2             0.3261      0.016     21.029      0.000         0.296     0.357
x3             0.1254      0.016      7.933      0.000         0.094     0.156
x4             0.1291      0.012     10.536      0.000         0.105     0.153
x5             0.0609      0.012      5.065      0.000         0.037     0.085
x6             0.2126      0.004     47.272      0.000         0.204     0.221
==============================================================================
Omnibus:                       10.831   Durbin-Watson:                   0.120
Prob(Omnibus):                  0.004   Jarque-Bera (JB):               10.859
Skew:                           0.212   Prob(JB):                      0.00439
Kurtosis:                       2.827   Cond. No.                         357.
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[Finished in 290.6s]
\end{verbatim}


\end{document}